# Event Logging Configuration
spark.eventLog.enabled                true
spark.loglevel                        OUTPUT
spark.eventLog.dir                    s3a://logging/spark-events/
spark.eventLog.compress               true

# History Server Configuration
spark.history.fs.logDirectory         s3a://logging/spark-events/
spark.history.ui.port                 18080
spark.history.fs.update.interval      10s
spark.history.fs.cleaner.enabled      true
spark.history.fs.cleaner.interval     7d
spark.history.fs.cleaner.maxAge       7d

# Network Configuration
# Advertise driver host so workers can connect to the driver's RPC
# When launching interactive clients from the master container, use
# `spark-master` which is resolvable by other containers on the compose
# network. For external submissions, set this to the driver's reachable
# host or use cluster deploy mode.
spark.driver.host                     spark-master
# Bind address for the driver process (0.0.0.0 to listen on all interfaces)
spark.driver.bindAddress             0.0.0.0

# MinIO S3 Configuration
# MinIO runs on minio:9000 (resolvable from Spark containers via docker network)
# Configure Spark to use MinIO as S3-compatible storage
spark.hadoop.fs.s3a.impl                                  org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.endpoint                              http://minio:9000
spark.hadoop.fs.s3a.access.key                            root_user
spark.hadoop.fs.s3a.secret.key                            root_password
spark.hadoop.fs.s3a.path.style.access                     true
spark.hadoop.fs.s3a.aws.credentials.provider              org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
spark.hadoop.fs.s3a.connection.ssl.enabled                false
spark.hadoop.fs.s3a.attempts.maximum                      3
spark.hadoop.fs.s3a.retry.interval.seconds                1

# Alternative: Use environment variables (MINIO_ACCESS_KEY, MINIO_SECRET_KEY)
# If using env vars, comment out the above access.key and secret.key lines
